from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse
import aiofiles
import os
from pptx import Presentation
import pytesseract
from pdf2image import convert_from_path, convert_from_bytes
from openai import OpenAI
from pydantic import BaseModel
import re
# from sentence_transformers import SentenceTransformer, util
from konlpy.tag import Okt
from typing import Dict
from pdf2image import convert_from_path
import requests
from fastapi.middleware.cors import CORSMiddleware


#pdf2image ì„¤ì •
poppler_path=r"C:/Users/jhs38/poppler-24.08.0/Library/bin"

# KorSBERT ëª¨ë¸, Okt í˜•íƒœì†Œ ë¶„ì„ê¸°
# model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
#okt = Okt()

#py -m pip install fastapi uvicorn aiofiles pdf2image pytesseract python-pptx openai konlpy
#py -m uvicorn main:app --reload --port 8000

# openai api key ì„¤ì •
client = OpenAI(api_key="") #api keyë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

#OCRìš© tesseract ê²½ë¡œ ì„¤ì •
pytesseract.pytesseract.tesseract_cmd = r"C:/Program Files/Tesseract-OCR/tesseract.exe"
    
# # Spring STT(Whisper) API ì—”ë“œí¬ì¸íŠ¸
# SPRING_STT_URL = "http://localhost:8080/api/whisper-multi" # Spring Boot ì„œë²„ì˜ STT API ì—”ë“œí¬ì¸íŠ¸

# ì˜ë„ ì¼ì¹˜ ì„ê³„ê°’
INTENT_THRESHOLD = 0.75


# stt ë¹„êµ í•¨ìˆ˜ ---------------------------------------------------------------------------------------------
class TextRequest(BaseModel):
    raw_text: str
    
# âœ… ì…ë ¥ ë°ì´í„° ëª¨ë¸
class CompareRequest(BaseModel):
    cue: str      # íì‹œíŠ¸ ë¬¸ì¥
    stt: str      # STT ê²°ê³¼ ë¬¸ì¥

# âœ… í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
# def get_keywords(text: str) -> set:
#     return set(okt.nouns(text))

class EvaluateAudioResponse(BaseModel):
    stt_text: str
    sentence_similarity: float
    intent_match: float
    keyword_coverage: float
    level: str       # â€œë†’ìŒâ€/â€œì¤‘ê°„â€/â€œë‚®ìŒâ€ ë“±ê¸‰


# í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì‚¬ í•¨ìˆ˜ --------------------------------------------------------------------------------------------


# ì˜ì–´ ë‹¨ì–´/ë¶ˆìš©ì–´ ê´€ë ¨ ì½”ë“œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
def clean_text(text):
    return re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text)

def filter_english_words(text):
    return re.findall(r'\b[a-zA-Z]{2,}\b', text)

def filter_korean_words(text):
    nouns = okt.nouns(text)
    return [n for n in nouns if len(n) > 1]

def extract_valid_words(text):
    text = clean_text(text)
    eng_words = filter_english_words(text)
    kor_words = filter_korean_words(text)
    return eng_words, kor_words
    
    
#í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ ----------------------------------------------------------------------------------------------

#pdf
def extract_text_from_pdf(pdf_input, from_bytes: bool = False) -> str:
    if from_bytes:
        images = convert_from_bytes(pdf_input)
    else:
        images = convert_from_path(pdf_input)
    full_text = ""
    for img in images:
        text = pytesseract.image_to_string(img, lang='kor+eng')
        full_text += text + "\n"
    return full_text


#pptx 
def extract_text_from_pptx(path: str) -> str:
    text = ""
    prs = Presentation(path)
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
            elif hasattr(shape, "text_frame") and shape.text_frame is not None:
                text += shape.text_frame.text + "\n"
    return text

# ë¬¸ì¥ ìœ ì‚¬ë„ì— ë”°ë¼ "ë†’ìŒ"/"ì¤‘ê°„"/"ë‚®ìŒ" ë“±ê¸‰ì„ ê²°ì •
def determine_level(similarity: float) -> str:
    if similarity >= 0.75:
        return "ë†’ìŒ"
    elif similarity >= 0.50:
        return "ì¤‘ê°„"
    else:
        return "ë‚®ìŒ"


# ìŠ¤í¬ë¦½íŠ¸ --------------------------------------------------------------------------------------------
def generate_presentation_script(slide_text: str) -> str:
    prompt = f"""
ë„ˆëŠ” ëŒ€í•™ìƒ ë°œí‘œìë£Œì—ì„œ ë°œí‘œìê°€ ì‚¬ìš©í•  ë°œí‘œ ëŒ€ë³¸ê³¼ ìš”ì•½ íì¹´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ìŠ¬ë¼ì´ë“œë³„ í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•´, ë°˜ë“œì‹œ ì•„ë˜ ì§€ì¹¨ê³¼ ì˜ˆì‹œë¥¼ ë”°ë¼ ë°œí‘œìë£Œ ëŒ€ë³¸ì„ ì‘ì„±í•´ ì¤˜.

---
[ì§€ì¹¨]
[0] ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ ìë™ ì§€ì •
- ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ ìŠ¬ë¼ì´ë“œë³„ ëª…í™•í•œ êµ¬ë¶„ì(ì˜ˆ: ì œëª©) ì—†ì´ë„, ê° ì£¼ìš” ì„¹ì…˜ ìˆœì„œëŒ€ë¡œ ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸(1, 2, 3, ...)ë¥¼ ë¶€ì—¬í•˜ì—¬ ëª¨ë“  ìŠ¬ë¼ì´ë“œë¥¼ ëˆ„ë½ ì—†ì´ ì²˜ë¦¬í•˜ì„¸ìš”.

[1] ê¸°ë³¸ë²„ì „
- ìŠ¬ë¼ì´ë“œì˜ í…ìŠ¤íŠ¸ì™€ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬, ê° í˜ì´ì§€(ìŠ¬ë¼ì´ë“œ)ë§ˆë‹¤ ë°œí‘œìê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
- ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê³  ë…¼ë¦¬ì ì¸ íë¦„ì„ ê°–ì¶”ë˜, ë‹¨ì •ì ì´ê³  ê³µì‹ì ì¸ ë°œí‘œì²´(ì˜ˆ: â€œ~ì…ë‹ˆë‹¤â€, â€œ~í•©ë‹ˆë‹¤â€)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- êµ¬ì–´ì²´(ì˜ˆ: â€œ~ê±°ë“ ìš”â€, â€œ~í•´ìš”â€, â€œ~ê°™ìŠµë‹ˆë‹¤â€)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ìŠ¬ë¼ì´ë“œ ì œëª©ë§Œì„ ì£¼ì œë¡œ ì‚¼ê±°ë‚˜, íŒŒì¼ëª…ìœ¼ë¡œ ë‚´ìš©ì„ ìœ ì¶”í•˜ì§€ ë§ˆì„¸ìš”.
- ë°œí‘œìê°€ ì‹¤ì œë¡œ ë§í•˜ì§€ ì•Šì„ ë‚´ìš©(ì˜ˆ: â€œì´ ìŠ¬ë¼ì´ë“œëŠ” ~ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤â€ ë“± ìŠ¬ë¼ì´ë“œ ì„¤ëª…ì´ë‚˜ í™”ë©´ ì•ˆë‚´)ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- í‘œì§€(1ë²ˆ ìŠ¬ë¼ì´ë“œ)ì—ì„œëŠ” ì¸ì‚¬ì™€ ë°œí‘œ ì£¼ì œë¥¼ ê°„ë‹¨í•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ìˆ˜ì¤€ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.
- OCR ì¸ì‹ì´ ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ëŠ” ìŠ¬ë¼ì´ë“œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•˜ì„¸ìš”:
    [ê¸°ë³¸ë²„ì „] (OCR ì¸ì‹ ë¶ˆê°€ - ìš”ì•½ ìƒëµ)
- ë°œí‘œ íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§ˆ ìˆ˜ ìˆë„ë¡, ê° ìŠ¬ë¼ì´ë“œ ë§ˆì§€ë§‰ ë¬¸ì¥ì€ ë‹¤ìŒ ë‚´ìš©ì„ ì˜ˆê³ í•˜ê±°ë‚˜, ì ì ˆí•œ ì—°ê²° ì–´ë¯¸ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
- ë°œí‘œìê°€ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì•„ë˜ ë¹„ì–¸ì–´ì  í‘œí˜„ ì•„ì´ì½˜ì„ ì ì ˆí•œ ìœ„ì¹˜(ê°•ì¡°, ì „í™˜, í˜¸í¡ ë“±)ì— ë°°ì¹˜í•˜ì„¸ìš”:
    ğŸ” ì²­ì¤‘ ë°”ë¼ë³´ê¸°
    ğŸ“„ ë°œí‘œìë£Œ ë³´ê¸°
    âœ‹ ì œìŠ¤ì²˜
    ğŸ‘‰ í™”ë©´ ê°€ë¦¬í‚¤ê¸°
    ğŸŒ¬ í˜¸í¡
    â“ ì§ˆì˜ì‘ë‹µ
- ì•„ì´ì½˜ì€ ì‹¤ì œ ë°œí‘œ íë¦„ì— ì–´ìš¸ë¦¬ëŠ” ìœ„ì¹˜ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…í•˜ì„¸ìš”.
    ì˜ˆì‹œ: ìŠ¬ë¼ì´ë“œ ì²« ë¬¸ì¥ ì•(í˜¸í¡/ì²­ì¤‘ ë°”ë¼ë³´ê¸°), ì¤‘ìš”í•œ ì •ë³´ ë’¤(í™”ë©´ ê°€ë¦¬í‚¤ê¸°/ì œìŠ¤ì²˜), ì£¼ì œ ì „í™˜ ì‹œ(í˜¸í¡/ìë£Œ ë³´ê¸°) ë“±

[2] ì‹¬í™”ë²„ì „
- í•´ë‹¹ ìŠ¬ë¼ì´ë“œì˜ í•µì‹¬ ì£¼ì œë¥¼ í•œë¬¸ì¥ìœ¼ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
- ìš”ì•½ë¬¸ì€ ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ, **í•µì‹¬ í‚¤ì›Œë“œë§Œ** í¬í•¨í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
- ì£¼ìš” ë©”ì‹œì§€ë¥¼ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡, ì„ ì–¸ë¬¸ ë˜ëŠ” ì„¤ëª…ë¬¸ í˜•íƒœë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
- ë¶ˆí•„ìš”í•œ ë¶€ì—°ì„¤ëª…ì€ í”¼í•˜ê³ , ë¬¸ì„œì˜ í•µì‹¬ ë…¼ì§€ì— ì§‘ì¤‘í•˜ì„¸ìš”.
- í‘œì§€(1ë²ˆ ìŠ¬ë¼ì´ë“œ)ëŠ” â€˜ì´ë²ˆ ë°œí‘œì˜ ëª©ì â€™ë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- OCR ì¸ì‹ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì•„ë˜ì²˜ëŸ¼ ì‘ì„±í•˜ì„¸ìš”:
    [ì‹¬í™”ë²„ì „] (OCR ì¸ì‹ ë¶ˆê°€ â€“ ìš”ì•½ ìƒëµ)

[3] ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ

ìŠ¬ë¼ì´ë“œ 1
[ê¸°ë³¸ë²„ì „]
ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ â€˜ì‚¬ì—… íƒ€ë‹¹ì„± ë¶„ì„â€™ì— ëŒ€í•´ ë°œí‘œí•  ê²½ì˜í•™ê³¼ 20210001 ê¹€ì§€ì›ì…ë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡
ì§€ê¸ˆë¶€í„° ë°œí‘œë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ğŸ” ì²­ì¤‘ ë°”ë¼ë³´ê¸°

[ì‹¬í™”ë²„ì „]
ë°œí‘œ ì£¼ì œ ì„¤ëª… ë° ìê¸°ì†Œê°œ

ìŠ¬ë¼ì´ë“œ 2
[ê¸°ë³¸ë²„ì „]
íƒ€ë‹¹ì„± ë¶„ì„ì€ ì‚¬ì—… ì•„ì´ë””ì–´ê°€ ì‹¤ì œë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œì§€ íŒë‹¨í•˜ëŠ” ì ˆì°¨ì…ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´ ì‚¬ì—…í™” ê°€ì¹˜ê°€ ìˆëŠ”ì§€ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‘‰ í™”ë©´ ê°€ë¦¬í‚¤ê¸°
ì´ì œ íƒ€ë‹¹ì„± ë¶„ì„ì˜ ì‹œê¸°ì™€ ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡

[ì‹¬í™”ë²„ì „]
íƒ€ë‹¹ì„±ë¶„ì„ ê°œë… ë° ëª©ì  ì„¤ëª…

ìŠ¬ë¼ì´ë“œ 3
[ê¸°ë³¸ë²„ì „]
íƒ€ë‹¹ì„± ë¶„ì„ì€ ì‚¬ì—… ì•„ì´ë””ì–´ì˜ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ì˜ˆë¹„ í‰ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ, ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•´ì•¼ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤.
ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ íˆ¬ì…ë˜ê¸° ì „ì— ì•„ì´ë””ì–´ë¥¼ ì„ ë³„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ğŸ” ì²­ì¤‘ ë°”ë¼ë³´ê¸°
ì¼ë¶€ ê¸°ì—…ê°€ëŠ” ì•„ì´ë””ì–´ íŒŒì•… í›„ ë°”ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ê°œë°œë¡œ ë„˜ì–´ê°€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. âœ‹ ì œìŠ¤ì²˜
íš¨ê³¼ì ì¸ íƒ€ë‹¹ì„± ë¶„ì„ì€ ì´ëŸ¬í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡

[ì‹¬í™”ë²„ì „]
íƒ€ë‹¤ì„± ë¶„ì„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ì´ˆê¸°ë‹¨ê³„ ìˆ˜í–‰í•´ì•¼í•˜ëŠ” ì¤‘ìš”ì„±ì„ ì„¤ëª…

[4] ì¶”ê°€ ì§€ì¹¨
- ê° ìŠ¬ë¼ì´ë“œë³„ë¡œ [ê¸°ë³¸ë²„ì „], [ì‹¬í™”ë²„ì „] ìˆœì„œë¡œ ë°˜ë“œì‹œ ì¶œë ¥í•˜ì„¸ìš”.
- í˜•ì‹, ì•„ì´ì½˜, ìŠ¬ë¼ì´ë“œ/ë²„ì „ ìˆœì„œë¥¼ ê¼­ ì§€ì¼œì£¼ì„¸ìš”.
- ì¶œë ¥ ê²°ê³¼ê°€ ìœ„ ì˜ˆì‹œì™€ ë‹¤ë¥´ê±°ë‚˜ í˜•ì‹ì´ ì–´ê¸‹ë‚˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.

---
[ìŠ¬ë¼ì´ë“œë³„ OCR ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼]
{slide_text}

---
[ìµœì¢… ì¶œë ¥]
"""
    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {
                "role": "system",
                "content": "ë„ˆëŠ” ì‹¤ì „ ë°œí‘œ íì¹´ë“œ/ëŒ€ë³¸ ìë™ ìƒì„± ì „ë¬¸ê°€ì•¼. ë°˜ë“œì‹œ ì˜ˆì‹œ í¬ë§·ê³¼ ì§€ì¹¨ì„ ì§€ì¼œì„œ, ë°œí‘œìê°€ ë°œí‘œìë£Œë§Œ ë³´ê³ ë„ ì™„ì„±ë„ ë†’ì€ ë°œí‘œë¥¼ í•  ìˆ˜ ìˆê²Œ ì‘ì„±í•´."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        temperature=0.1
    )
    return response.choices[0].message.content.strip()

#â”€â”€â”€(GPTì—ê²Œ ì§ì ‘ ë¹„êµ ìš”ì²­í•˜ëŠ” í—¬í¼ í•¨ìˆ˜)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def gpt_compare(cue: str, stt: str) -> Dict:
    """
    GPTì—ê²Œ 'cue'ì™€ 'stt' ë‘ ë¬¸ì¥ì„ ì£¼ê³ ,
    JSON í˜•íƒœ(í‚¤: sentence_similarity, intent_match, keyword_coverage, level)ë¡œ
    ê²°ê³¼ë§Œ ë”± ë¦¬í„´í•´ ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤.
    """
    prompt = f"""
ì•„ë˜ ë‘ ë¬¸ì¥(ê¸°ì¤€ ë¬¸ì¥, STT ê²°ê³¼ ë¬¸ì¥)ì— ëŒ€í•´ ë‹¤ìŒ ë„¤ ê°€ì§€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³ , JSON ê°ì²´ í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

1) sentence_similarity: 0.00ì—ì„œ 1.00 ì‚¬ì´ì˜ ìˆ«ìë¡œ, ë‘ ë¬¸ì¥ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚´ì„¸ìš”.
   - 1.00: ì˜ë¯¸ê°€ ê±°ì˜ ë™ì¼
   - 0.00: ì „í˜€ ë‹¤ë¥¸ ì˜ë¯¸

2) intent_match: 0.00ì—ì„œ 1.00 ì‚¬ì´ì˜ ìˆ«ìë¡œ, ë‘ ë¬¸ì¥ì˜ ì˜ë„ê°€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ì„¸ìš”.
   - ì˜ˆ: ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ì˜ë„ê°€ ê°™ë‹¤ë©´ 1.00, ì™„ì „íˆ ë‹¤ë¥´ë©´ 0.00

3) keyword_coverage: 0.00ì—ì„œ 1.00 ì‚¬ì´ì˜ ìˆ«ìë¡œ, ê¸°ì¤€ ë¬¸ì¥(cue)ì— ìˆëŠ” í•µì‹¬ í‚¤ì›Œë“œê°€ STT ë¬¸ì¥ì— ì–¼ë§ˆë‚˜ í¬í•¨ë˜ì—ˆëŠ”ì§€ ë¹„ìœ¨ë¡œ ë‚˜íƒ€ë‚´ì„¸ìš”.
   - í•µì‹¬ í‚¤ì›Œë“œëŠ” GPTê°€ ë¬¸ë§¥ì„ ë³´ê³  ì¶”ì¶œí•˜ë„ë¡ í•˜ì„¸ìš”.

4) level: ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ "ë†’ìŒ" / "ì¤‘ê°„" / "ë‚®ìŒ" ì¤‘ í•˜ë‚˜ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
   - sentence_similarityê°€ 0.75 ì´ìƒì´ë©´ "ë†’ìŒ"
   - 0.50 ì´ìƒ 0.75 ë¯¸ë§Œì´ë©´ "ì¤‘ê°„"
   - ê·¸ ì™¸ì—ëŠ” "ë‚®ìŒ"

ë°˜í™˜ ì˜ˆì‹œ(JSONë§Œ ì¶œë ¥; ì¶”ê°€ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ ì—†ì´ ë”± JSON):

[ê¸°ì¤€ ë¬¸ì¥]
"{cue}"

[STT ê²°ê³¼ ë¬¸ì¥]
"{stt}"
"""
    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.0
    )
    content = response.choices[0].message.content.strip()

    # GPTê°€ ì¶œë ¥í•œ JSONë§Œ íŒŒì‹±
    try:
        import json
        return json.loads(content)
    except Exception:
        # JSON íŒŒì‹± ì˜¤ë¥˜ ì‹œ, ë§¤ìš° ê°„ë‹¨íˆ ìˆ«ìì™€ ë ˆë²¨ì„ ì¶”ì¶œ
        # (ì‹¤ ì‹œì—°ì—ì„œëŠ” JSON í˜•ì‹ ì˜ ì§€ì¼œë‹¬ë¼ê³  Promptsì— ê°•ì¡°í•˜ë©´ ë¨)
        m = {}
        nums = re.findall(r'"sentence_similarity"\s*:\s*([0-9.]+)', content)
        m["sentence_similarity"] = float(nums[0]) if nums else 0.0
        
        # nums = re.findall(r'"intent_match"\s*:\s*([0-9.]+)', content)
        # m["intent_match"] = float(nums[0]) if nums else 0.0
        # nums = re.findall(r'"keyword_coverage"\s*:\s*([0-9.]+)', content)
        # m["keyword_coverage"] = float(nums[0]) if nums else 0.0
        
        lvl = re.search(r'"level"\s*:\s*"([^"]+)"', content)
        m["level"] = lvl.group(1) if lvl else ""
        return m


# â”€â”€â”€(FastAPI ì•± ì •ì˜)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app = FastAPI(
    title="í†µí•© OCRÂ·íì¹´ë“œ ìƒì„±Â·STT ë¹„êµ API",
    description="PDF/PPTXì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ, ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±, STT vs íì‹œíŠ¸ ë¹„êµë¥¼ í•œ ê³³ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],    # ë‚˜ì¤‘ì— ìš´ì˜ í™˜ê²½ì— ë§ê²Œ ë„ë©”ì¸ ì§€ì •
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def root():
    return {"message": "API is running"}


@app.post("/extract_words/pdf")
async def extract_words_from_pdf(file: UploadFile = File(...)):
    """
    PDF â†’ OCR(text) â†’ ì˜ì–´/í•œêµ­ì–´ ë‹¨ì–´ ì§‘í•© ë°˜í™˜
    """
    contents = await file.read()
    full_text = extract_text_from_pdf(contents, from_bytes=True)
    eng_words, kor_words = extract_valid_words(full_text)
    return JSONResponse(content={
        "english_words": eng_words,
        "korean_words": kor_words
    })


@app.post("/extract-text-pdf-pptx/")
async def extract_ocr_text(file: UploadFile = File(...)):
    """
    ì—…ë¡œë“œëœ PDF/PPTX â†’ OCR/text ì¶”ì¶œ í›„ ë°˜í™˜
    """
    filename = file.filename
    ext = filename.rsplit(".", 1)[-1].lower()
    saved_path = os.path.join(UPLOAD_DIR, filename)

    async with aiofiles.open(saved_path, "wb") as out_file:
        await out_file.write(await file.read())

    try:
        if ext == "pdf":
            text = extract_text_from_pdf(saved_path, from_bytes=False)
        elif ext == "pptx":
            text = extract_text_from_pptx(saved_path)
        else:
            raise HTTPException(status_code=400, detail="PDF ë˜ëŠ” PPTXë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
        return JSONResponse({
            "filename": filename,
            "text_by_ocr": text
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/generate-presentation-script/")
async def generate_presentation_script_api(req: TextRequest):
    """
    ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸(raw_text) â†’ ë°œí‘œ ëŒ€ë³¸ & íì¹´ë“œ ìë™ ìƒì„±
    """
    raw = req.raw_text
    if not raw.strip():
        raise HTTPException(status_code=400, detail="raw_textê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        result = generate_presentation_script(raw)
        return JSONResponse({
            "presentation_script": result
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


# @app.post("/evaluate", summary="íì‹œíŠ¸ vs STT ë¹„êµ (ë¬¸ìì—´ ì…ë ¥)", response_model=Dict[str, float])
# def evaluate_similarity(data: CompareRequest):
#     """
#     ìš”ì²­ JSON: { "cue": "...", "stt": "..." }
#     - 1) KorSBERT ì½”ì‚¬ì¸ ìœ ì‚¬ë„
#     - 2) Threshold(0.75) ê¸°ë°˜ ì˜ë„ ì¼ì¹˜ (1.0/0.0)
#     - 3) í‚¤ì›Œë“œ í¬í•¨ë¥ (ìì¹´ë“œ ìœ ì‚¬ë„)
#     """
#     cue = data.cue
#     stt = data.stt

#     # 1. KorSBERTë¡œ ì„ë² ë”© â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
#     emb = model.encode([cue, stt])
#     similarity = float(util.cos_sim(emb[0], emb[1])[0][0])

#     # 2. ì˜ë„ ì¼ì¹˜(Threshold)
#     intent_match = 1.0 if similarity >= INTENT_THRESHOLD else 0.0

#     # 3. í‚¤ì›Œë“œ í¬í•¨ë¥  (ìì¹´ë“œ ìœ ì‚¬ë„)
#     cue_keywords = get_keywords(cue)
#     stt_keywords = get_keywords(stt)
#     intersection = cue_keywords & stt_keywords
#     union = cue_keywords | stt_keywords
#     keyword_coverage = len(intersection) / len(union) if union else 0.0

#     return {
#         "sentence_similarity": round(similarity, 4),
#         "intent_match": intent_match,
#         "keyword_coverage": round(keyword_coverage, 4)
#     }


# @app.post(
#     "/evaluate-with-audio",
#     summary="íì‹œíŠ¸ ë¬¸ì¥ + ì˜¤ë””ì˜¤ íŒŒì¼(STT) â†’ GPT ë¹„êµ",
#     response_model=EvaluateAudioResponse
# )
# async def evaluate_with_audio(
#     cue: str = Form(..., description="ë¹„êµí•  ê¸°ì¤€(íì‹œíŠ¸) ë¬¸ì¥"),
#     audio: UploadFile = File(..., description="STT ëŒ€ìƒ ì˜¤ë””ì˜¤ íŒŒì¼ (ì˜ˆ: WAV)")
# ):
#     # 1) ì˜¤ë””ì˜¤ íŒŒì¼ ì„ì‹œ ì €ì¥
#     temp_path = os.path.join(UPLOAD_DIR, f"temp_{audio.filename}")
#     async with aiofiles.open(temp_path, "wb") as out_file:
#         await out_file.write(await audio.read())

#     # 2) Spring STT API í˜¸ì¶œí•´ì„œ stt_text ë°›ì•„ì˜¤ê¸°
#     try:
#         with open(temp_path, "rb") as f:
#             files = {"audio": f}
#             resp = requests.post(SPRING_STT_URL, files=files, timeout=60)
#             resp.raise_for_status()
#     except Exception as e:
#         if os.path.exists(temp_path):
#             os.remove(temp_path)
#         raise HTTPException(status_code=500, detail=f"STT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

#     data = resp.json()
#     stt_text = data.get("result", "").strip()

#     # 3) ì„ì‹œ íŒŒì¼ ì‚­ì œ
#     if os.path.exists(temp_path):
#         os.remove(temp_path)

#     # 4) GPTì—ê²Œ ë¹„êµ ìš”ì²­
#     r = gpt_compare(cue, stt_text)

#     # 5) GPTê°€ ë§Œë“¤ì–´ì¤€ ê²°ê³¼ë¥¼ EvaluateAudioResponse í˜•íƒœë¡œ ë°˜í™˜
#     return EvaluateAudioResponse(
#         stt_text=stt_text,
#         sentence_similarity=r.get("sentence_similarity", 0.0),
#         intent_match=r.get("intent_match", 0.0),
#         keyword_coverage=r.get("keyword_coverage", 0.0),
#         level=r.get("level", "")
#     )

@app.post(
    "/evaluate-with-audio",
    summary="íì‹œíŠ¸ ë¬¸ì¥ + ì˜¤ë””ì˜¤ íŒŒì¼(STT) â†’ GPT ë¹„êµ",
    response_model=EvaluateAudioResponse
)
async def evaluate_with_audio(
    cue: str = Form(..., description="ë¹„êµí•  ê¸°ì¤€(íì‹œíŠ¸) ë¬¸ì¥"),
    audio: UploadFile = File(..., description="STT ëŒ€ìƒ ì˜¤ë””ì˜¤ íŒŒì¼ (ì˜ˆ: WAV)")
):
    # ì˜¤ë””ì˜¤ íŒŒì¼ ì„ì‹œ ì €ì¥
    temp_path = os.path.join(UPLOAD_DIR, f"temp_{audio.filename}")
    async with aiofiles.open(temp_path, "wb") as out_file:
        await out_file.write(await audio.read())

    # ì—¬ê¸°ë¶€í„° ì˜ˆì™¸ê°€ ë°œìƒí•˜ë©´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë°”ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    try:
        # 1) Whisper API í˜¸ì¶œ ë¶€ë¶„
        with open(temp_path, "rb") as fbin:
            whisper_resp = client.audio.transcriptions.create(
                file=fbin,
                model="whisper-1"
            )
        # Whisper ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ êº¼ë‚´ê¸°
        stt_text = whisper_resp.text.strip()

        # 2) ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_path):
            os.remove(temp_path)

        # 3) GPT ë¹„êµ
        r = gpt_compare(cue, stt_text)

        return EvaluateAudioResponse(
            stt_text=stt_text,
            sentence_similarity=r.get("sentence_similarity", 0.0),
            #intent_match=r.get("intent_match", 0.0),
            #keyword_coverage=r.get("keyword_coverage", 0.0),
            level=r.get("level", "")
        )

    except Exception as e:
        # ì˜ˆì™¸ ë©”ì‹œì§€ë¥¼ ìì„¸íˆ ë‚¨ê¸°ê³  500ìœ¼ë¡œ ì‘ë‹µ
        # ì‹¤ì œ ì‹œì—°ì´ ëë‚˜ë©´ eë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ëŠ” ì½”ë“œëŠ” ì‚­ì œí•˜ì„¸ìš”.
        detail_msg = f"ì˜ˆì™¸ ë°œìƒ: {type(e).__name__} â€“ {e}"
        # ì„ì‹œ íŒŒì¼ë„ ë‚¨ì§€ ì•Šë„ë¡ ì‚­ì œ
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise HTTPException(status_code=500, detail=detail_msg)

# ì‹œì—°ìš© test API

# ì‹œì—°ìš©ìœ¼ë¡œ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë‘” ì¹´ë“œ ë°ì´í„°
DEMO_CARDS = [
    { "title": "ìŠ¬ë¼ì´ë“œ 1", 
     "content":  " \n[ê¸°ë³¸ë²„ì „]  \n\nì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ ëŒ€í•™ìƒ ë°œí‘œ ë¶ˆì•ˆê³¼ ê·¸ í•´ê²° ë°©ì•ˆì— ëŒ€í•´ ë°œí‘œí•˜ê² ìŠµë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡  \në°œí‘œ ì£¼ì œëŠ” ëŒ€í•™ìƒë“¤ì´ ë°œí‘œë¥¼ ì¤€ë¹„í•˜ê³  ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ê²ªëŠ” ì–´ë ¤ì›€ê³¼ ì´ë¥¼ ê·¹ë³µí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ğŸ” ì²­ì¤‘ ë°”ë¼ë³´ê¸°\n\n\n \në°œí‘œ ë¶ˆì•ˆì€ ë°œí‘œí•  ë‚´ìš©ì„ ê¸°ì–µí•˜ì§€ ëª»í•˜ê±°ë‚˜, ë§ì´ ë– ì˜¤ë¥´ì§€ ì•Šê±°ë‚˜, ì‚¬ëŒë“¤ ì•ì—ì„œ ë§í•˜ëŠ” ê²ƒì„ í”¼í•˜ê²Œ ë˜ëŠ” ë‘ë ¤ì›€ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. âœ‹ ì œìŠ¤ì²˜  \nì´ëŸ¬í•œ ë‘ë ¤ì›€ì€ ë°œí‘œ ì—°ë‹¨ì—ì„œì˜ ìì‹ ê° ì €í•˜ì™€ ë°œí‘œ ì‹¤íŒ¨ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡  \nì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ì ì ˆí•œ ì¤€ë¹„ì™€ ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ğŸ“„ ë°œí‘œìë£Œ ë³´ê¸°\n\n  \n  \nëŒ€í•™ ì‹ ì…ìƒ 117ëª…ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì„¤ë¬¸ì¡°ì‚¬ ê²°ê³¼, 69.6%ê°€ ë°œí‘œ ìˆ˜ì—…ì´ ë¶€ë‹´ìŠ¤ëŸ½ë‹¤ê³  ì‘ë‹µí–ˆìŠµë‹ˆë‹¤. ğŸ” ì²­ì¤‘ ë°”ë¼ë³´ê¸°  \në˜í•œ, 62.4%ëŠ” ëª¨ë“  ë¬¸ì¥ì„ ë¯¸ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‘ì„±í•œë‹¤ê³  ë‹µë³€í–ˆìœ¼ë©°, ì´ëŠ” ë°œí‘œ ì¤€ë¹„ì˜ í•œ ë°©ë²•ì…ë‹ˆë‹¤. ğŸŒ¬ í˜¸í¡  \nì´ëŸ¬í•œ ì¡°ì‚¬ ê²°ê³¼ëŠ” ë°œí‘œ ë¶ˆì•ˆì„ ì¤„ì´ê¸° ìœ„í•œ ì „ëµ ìˆ˜ë¦½ì— ì¤‘ìš”í•œ ìë£Œê°€ ë©ë‹ˆë‹¤. ğŸ“„ ë°œí‘œìë£Œ ë³´ê¸°\n\n" }]

@app.post("/api/qcards")
async def demo_qcards():
    return JSONResponse(content={ "data": DEMO_CARDS })


# ìš”ì²­ ë°”ë”” ìŠ¤í‚¤ë§ˆ
class EvaluateTextRequest(BaseModel):
    cue: str
    transcripts: list[str]

# ì‘ë‹µ í•­ëª© ìŠ¤í‚¤ë§ˆ
class EvaluateResponse(BaseModel):
    sentence_similarity: float
    level: str
    # í•„ìš”í•˜ë©´ intent_match, keyword_coverage ë“± ì¶”ê°€

@app.post("/api/evaluate", response_model=list[EvaluateResponse])
async def evaluate_text(req: EvaluateTextRequest):
    try:
        # cue, transcripts ë°›ìŒ
        cue = req.cue
        transcripts = req.transcripts

        # gpt_compare ëŠ” cueì™€ ë‹¨ì¼ ë¬¸ì¥ì„ ë°›ì•„ì„œ
        # {"sentence_similarity":..., "level":...} ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        results = [gpt_compare(cue, stt) for stt in transcripts]

        return results

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
